"""
Smart Bin SI - D√©tecteur YOLO avec apprentissage au fur et √† mesure
- D√©tecte les objets via cam√©ra
- Demande ta validation : si tu dis "oui c'est correct", l'image est sauvegard√©e pour r√©entra√Æner le mod√®le
- Utilise waste_classifier pour le tri (DB + Arduino)
"""

import cv2
import torch
import time
import numpy as np
from pathlib import Path
from datetime import datetime

import waste_classifier
from config import (
    MODEL_PATH, CONFIDENCE_THRESHOLD, IOU_THRESHOLD,
    CAMERA_SOURCE, USE_CSI_CAMERA, FRAME_WIDTH, FRAME_HEIGHT, SHOW_DISPLAY,
    AUTO_SORT_DELAY, MIN_DETECTIONS, LEARNING_MODE, SAVE_IMAGES,
    TRAINING_DIR, BIN_COLORS,
)
from config import ADMIN_AUTOSTART, ADMIN_INTERFACE_PORT, USER_INTERFACE_PORT
import socket
import subprocess
import sys
import os
# Essayer de forcer la sortie en UTF-8 (√©vite UnicodeEncodeError sur Windows)
try:
    sys.stdout.reconfigure(encoding='utf-8')
except Exception:
    try:
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    except Exception:
        pass


# ============================================
# SUPPORT CAM√âRA CSI JETSON
# ============================================

def get_csi_pipeline(camera_id=0, width=640, height=480, fps=30):
    """
    Cr√©er un pipeline GStreamer pour cam√©ra CSI Jetson
    
    Args:
        camera_id: ID du capteur cam√©ra (0 ou 1)
        width: Largeur de l'image
        height: Hauteur de l'image
        fps: Fr√©quence d'images
    
    Retourne:
        str: Cha√Æne de pipeline GStreamer
    """
    return (
        f"nvarguscamerasrc sensor-id={camera_id} ! "
        f"video/x-raw(memory:NVMM), width={width}, height={height}, "
        f"format=NV12, framerate={fps}/1 ! "
        f"nvvidconv flip-method=0 ! "
        f"video/x-raw, width={width}, height={height}, format=BGRx ! "
        f"videoconvert ! "
        f"video/x-raw, format=BGR ! appsink"
    )


# ============================================
# CLASSE D√âTECTEUR DE D√âCHETS
# ============================================

class WasteDetector:
    """
    Syst√®me de d√©tection de d√©chets bas√© sur YOLO
    Utilise waste_classifier pour la logique de tri
    """
    
    def __init__(self, model_path=MODEL_PATH):
        """
        Initialiser le d√©tecteur YOLO
        
        Args:
            model_path: Chemin vers les poids YOLO entra√Æn√©s (fichier .pt)
        """
        print("\n" + "="*50)
        print("ü§ñ SMART BIN SI - D√âTECTEUR YOLO")
        print("="*50)
        
        # Charger le mod√®le YOLO
        self.model = self.load_model(model_path)
        
        # Suivi des d√©tections
        self.last_detection = None
        self.detection_count = 0
        self.last_sort_time = 0
        self.last_frame = None  # Pour sauvegarder l'image lors de corrections
        
        # Initialiser les connexions via waste_classifier
        waste_classifier.init_serial_connection()
        waste_classifier.init_database()
        
        # Dossier pour les images d'apprentissage (quand tu confirmes "correct")
        if SAVE_IMAGES:
            TRAINING_DIR.mkdir(parents=True, exist_ok=True)
        
        print("‚úì D√©tecteur initialis√©\n")
    
    def load_model(self, model_path):
        """
        Charger le mod√®le YOLO depuis un fichier
        Supporte YOLOv5 et YOLOv8 via torch.hub ou ultralytics
        """
        print(f"üì¶ Chargement du mod√®le depuis : {model_path}")
        # Premi√®re tentative : utiliser l'API ultralytics (si install√©e)
        try:
            from ultralytics import YOLO
            # Si le mod√®le custom existe, on l'utilise, sinon on prend le yolov5s fourni au repo
            if Path(model_path).exists():
                model_file = str(model_path)
            else:
                model_file = str(Path(__file__).resolve().parent.parent / 'yolov5s.pt')

            try:
                model = YOLO(model_file)
                self._use_ultralytics = True
                print(f"‚úì Mod√®le charg√© via ultralytics ({model_file})")
            except Exception as e_load:
                # Cas fr√©quent : checkpoint YOLOv5 incompatible avec ultralytics (module manquant)
                print(f"[WARN] impossible de charger '{model_file}' via ultralytics: {e_load}")
                print("‚Üí Retraitement: utilisation d'un mod√®le ultralytics officiel l√©ger (yolov8n.pt)")
                model = YOLO('yolov8n.pt')
                self._use_ultralytics = True
                print("‚úì Mod√®le yolov8n charg√© via ultralytics (fallback)")
        except Exception as e_ultra:
            print(f"[WARN] ultralytics non disponible ou erreur: {e_ultra}")
            # Fallback : essayer torch.hub (ancienne m√©thode)
            try:
                if Path(model_path).exists():
                    model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)
                else:
                    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
                self._use_ultralytics = False
                print("‚úì Mod√®le charg√© via torch.hub (ultralytics/yolov5)")
            except Exception as e_hub:
                print(f"‚úó Erreur lors du chargement du mod√®le : {e_hub}")
                raise

        # Note : pour ultralytics on passera conf/iou au moment de l'appel d'inf√©rence.
        # Pour torch.hub (yolov5), on laisse les attributs si disponibles.
        try:
            if hasattr(model, 'conf'):
                model.conf = CONFIDENCE_THRESHOLD
            if hasattr(model, 'iou'):
                model.iou = IOU_THRESHOLD
        except Exception:
            pass

        # Si CUDA disponible, on essayera d'activer (uniquement si l'objet le supporte)
        try:
            if torch.cuda.is_available():
                if hasattr(model, 'to'):
                    model = model.to('cuda')
                print("‚úì Acc√©l√©ration GPU activ√©e")
            else:
                print("‚ö† Ex√©cution sur CPU (plus lent)")
        except Exception:
            pass

        return model
    
    def detect_waste(self, frame):
        """
        Ex√©cuter la d√©tection YOLO sur une image
        
        Args:
            frame: Image OpenCV (format BGR)
        
        Retourne:
            results: R√©sultats de d√©tection YOLO
        """
        # Ex√©cuter l'inf√©rence
        # Si on utilise ultralytics, passer conf/iou en param√®tres
        try:
            if getattr(self, '_use_ultralytics', False):
                results = self.model(frame, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD)
            else:
                results = self.model(frame)
        except TypeError:
            # Cas o√π le mod√®le n'accepte pas ces kwargs
            results = self.model(frame)
        return results
    
    def process_detections(self, results):
        """
        Traiter les r√©sultats YOLO et extraire les d√©chets
        
        Args:
            results: R√©sultats de d√©tection YOLO
        
        Retourne:
            list: D√©chets d√©tect√©s avec [nom_classe, confiance, bbox]
        """
        detections = []
        # Extraire les r√©sultats selon le backend utilis√©
        try:
            if getattr(self, '_use_ultralytics', False):
                # ultralytics retourne souvent une liste de Results ou un Results
                res = results[0] if isinstance(results, list) else results
                boxes = getattr(res, 'boxes', None)
                if boxes is not None:
                    # boxes.xyxy, boxes.conf, boxes.cls
                    try:
                        xyxy = boxes.xyxy.cpu().numpy()
                    except Exception:
                        xyxy = boxes.xyxy.numpy() if hasattr(boxes.xyxy, 'numpy') else []
                    try:
                        confs = boxes.conf.cpu().numpy()
                    except Exception:
                        confs = boxes.conf.numpy() if hasattr(boxes.conf, 'numpy') else []
                    try:
                        cls_idx = boxes.cls.cpu().numpy().astype(int)
                    except Exception:
                        cls_idx = boxes.cls.numpy().astype(int) if hasattr(boxes.cls, 'numpy') else []

                    for i, bbox in enumerate(xyxy):
                        x1, y1, x2, y2 = [float(v) for v in bbox]
                        confidence = float(confs[i]) if i < len(confs) else 0.0
                        cls = int(cls_idx[i]) if i < len(cls_idx) else 0
                        class_name = None
                        if hasattr(self.model, 'names'):
                            try:
                                class_name = self.model.names[cls]
                            except Exception:
                                class_name = str(cls)
                        else:
                            class_name = str(cls)

                        detections.append({
                            'class': class_name,
                            'confidence': confidence,
                            'bbox': [x1, y1, x2, y2]
                        })
                else:
                    # Pas de boxes ‚Üí pas de d√©tections
                    return []
            else:
                # Ancien format (torch.hub / yolov5)
                try:
                    predictions = results.pandas().xyxy[0]
                    for idx, row in predictions.iterrows():
                        class_name = row['name']
                        confidence = row['confidence']
                        bbox = [row['xmin'], row['ymin'], row['xmax'], row['ymax']]
                        detections.append({
                            'class': class_name,
                            'confidence': confidence,
                            'bbox': bbox
                        })
                except Exception:
                    pred = results.xyxy[0].cpu().numpy()
                    for detection in pred:
                        x1, y1, x2, y2, conf, cls = detection
                        class_name = self.model.names[int(cls)] if hasattr(self.model, 'names') else str(int(cls))
                        detections.append({
                            'class': class_name,
                            'confidence': float(conf),
                            'bbox': [float(x1), float(y1), float(x2), float(y2)]
                        })
        except Exception as e:
            print(f"‚ö† Erreur extraction d√©tections: {e}")
            return []
        
        return detections
    
    def should_trigger_sort(self, detection):
        """
        D√©cider si on doit d√©clencher l'action de tri
        Utilise un filtrage temporel pour √©viter les faux positifs
        
        Args:
            detection: Dictionnaire de d√©tection actuel
        
        Retourne:
            bool: True si on doit trier maintenant
        """
        current_time = time.time()
        
        # V√©rifier si assez de temps s'est √©coul√© depuis le dernier tri
        if current_time - self.last_sort_time < AUTO_SORT_DELAY:
            return False
        
        # V√©rifier si le m√™me objet est d√©tect√© plusieurs fois
        if detection and self.last_detection:
            if detection['class'] == self.last_detection['class']:
                self.detection_count += 1
            else:
                self.detection_count = 1
                self.last_detection = detection
        else:
            self.detection_count = 1
            self.last_detection = detection
        
        # D√©clencher si le minimum de d√©tections cons√©cutives est atteint
        if self.detection_count >= MIN_DETECTIONS:
            self.detection_count = 0
            self.last_sort_time = current_time
            return True
        
        return False
    
    def get_bin_color_for_display(self, waste_class):
        """
        Obtenir la couleur du bac pour l'affichage (sans trier)
        
        Args:
            waste_class: Nom de la classe de d√©chet
        
        Retourne:
            str: Couleur du bac ou None
        """
        # Chercher en base de donn√©es sans sauvegarder
        bin_color = waste_classifier.get_bin_color(waste_class)
        return bin_color
    
    def draw_detections(self, frame, detections):
        """
        Dessiner les bo√Ætes de d√©tection et labels sur l'image
        
        Args:
            frame: Image OpenCV
            detections: Liste des dictionnaires de d√©tection
        
        Retourne:
            frame: Image annot√©e
        """
        for det in detections:
            x1, y1, x2, y2 = [int(v) for v in det['bbox']]
            class_name = det['class']
            confidence = det['confidence']
            
            # Obtenir la couleur du bac pour ce d√©chet (juste pour affichage)
            bin_color = self.get_bin_color_for_display(class_name)
            
            color = BIN_COLORS.get(bin_color, BIN_COLORS["unknown"])
            
            # Dessiner la bo√Æte
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # Dessiner le label
            label = f"{class_name} ({confidence:.2f})"
            if bin_color:
                label += f" -> {bin_color}"
            else:
                label += " -> ?"
            
            # Fond pour le texte
            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            cv2.rectangle(frame, (x1, y1-text_height-10), (x1+text_width, y1), color, -1)
            
            # Texte
            cv2.putText(frame, label, (x1, y1-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        
        return frame
    
    def save_image_for_training(self, frame, class_name, bbox=None, class_id=None, correct=True):
        """
        Sauvegarde une image pour le r√©entra√Ænement YOLO.
        Quand tu confirmes que la d√©tection est correcte, l'image est stock√©e
        dans data/training_images/<class_name>/ (+ fichier .txt YOLO si bbox fourni).
        
        Args:
            frame: Image √† sauvegarder
            class_name: Nom de la classe (ex: plastic_bottle)
            bbox: [x1, y1, x2, y2] optionnel ‚Üí g√©n√®re un .txt au format YOLO
            class_id: index de la classe (pour le .txt YOLO)
            correct: True = bonne d√©tection, False = erreur (sauvegard√© dans _errors/)
        """
        if not SAVE_IMAGES:
            return
        class_name = class_name.strip().lower().replace(" ", "_")
        if correct:
            folder = TRAINING_DIR / class_name
        else:
            folder = TRAINING_DIR / "_errors" / class_name
        folder.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        prefix = "ok" if correct else "err"
        base = f"{prefix}_{timestamp}"
        filename = folder / f"{base}.jpg"
        cv2.imwrite(str(filename), frame)
        # Fichier label YOLO (une ligne : class_id x_center y_center width height, normalis√© 0-1)
        if bbox is not None and class_id is not None and len(bbox) == 4:
            h, w = frame.shape[:2]
            x1, y1, x2, y2 = [float(x) for x in bbox]
            x_center = ((x1 + x2) / 2) / w
            y_center = ((y1 + y2) / 2) / h
            width = (x2 - x1) / w
            height = (y2 - y1) / h
            label_path = folder / f"{base}.txt"
            with open(label_path, "w") as f:
                f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
        print(f"üíæ Image sauvegard√©e pour apprentissage : {filename.name} ({class_name})")
    
    def _class_name_to_id(self, class_name):
        """Retourne l'index de la classe dans le mod√®le (pour le label YOLO)."""
        if not hasattr(self.model, "names"):
            return None
        names = self.model.names  # dict int -> str
        for idx, name in names.items():
            if name == class_name:
                return idx
        return None

    def handle_correction(self, frame, best_detection):
        """
        Demande si la d√©tection est correcte ; si oui, sauvegarde l'image (+ label YOLO) pour r√©entra√Ænement.
        
        Args:
            frame: Image actuelle
            best_detection: dict avec 'class', 'confidence', 'bbox'
        """
        detected_class = best_detection["class"]
        bbox = best_detection.get("bbox")
        class_id = self._class_name_to_id(detected_class)
        
        print(f"\n‚ö† YOLO a d√©tect√© : '{detected_class}'")
        print("Est-ce correct ?")
        print("  y - Oui, c'est correct ‚Üí image sauvegard√©e pour am√©liorer le mod√®le")
        print("  n - Non, corriger le nom")
        print("  skip - Ignorer")
        
        choice = input("Votre choix : ").strip().lower()
        
        if choice == 'y':
            print("‚úì D√©tection confirm√©e ‚Üí image sauvegard√©e pour r√©entra√Ænement")
            self.save_image_for_training(
                frame, detected_class, bbox=bbox, class_id=class_id, correct=True
            )
            return detected_class
        
        elif choice == 'n':
            print("\nQuel est le vrai nom de cet objet ?")
            correct_name = input("Nom correct : ").strip()
            
            if correct_name:
                correct_name = correct_name.strip().lower().replace(" ", "_")
                self.save_image_for_training(frame, correct_name, correct=True)
                self.save_image_for_training(frame, detected_class, correct=False)
                print(f"‚úì Correction enregistr√©e : {detected_class} ‚Üí {correct_name}")
                return correct_name
        
        print("‚äò D√©tection ignor√©e")
        return None
    
    def run_camera_detection(self):
        """
        Boucle principale : capturer images, d√©tecter d√©chets, d√©clencher tri
        """
        # Initialiser la cam√©ra
        if USE_CSI_CAMERA:
            print("üì∑ Ouverture cam√©ra CSI...")
            pipeline = get_csi_pipeline(width=FRAME_WIDTH, height=FRAME_HEIGHT)
            cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
        else:
            print(f"üì∑ Ouverture cam√©ra : {CAMERA_SOURCE}")
            cap = cv2.VideoCapture(CAMERA_SOURCE)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)
        
        if not cap.isOpened():
            print("‚úó √âchec d'ouverture de la cam√©ra")
            return
        
        print("‚úì Cam√©ra pr√™te")
        print("\n" + "="*50)
        print("CONTR√îLES :")
        print("  'q' - Quitter")
        print("  's' - Forcer le tri de la d√©tection actuelle")
        print("  'r' - R√©initialiser le compteur de d√©tections")
        if LEARNING_MODE:
            print("  'c' - Corriger la derni√®re d√©tection")
        print("  'stats' - Voir les statistiques")
        print("="*50 + "\n")
        
        fps_time = time.time()
        fps_counter = 0
        fps_display = 0
        
        try:
            while True:
                # Capturer l'image
                ret, frame = cap.read()
                if not ret:
                    print("‚úó √âchec de lecture de l'image")
                    break
                
                # Sauvegarder la derni√®re frame pour corrections
                self.last_frame = frame.copy()
                
                # Ex√©cuter la d√©tection YOLO
                results = self.detect_waste(frame)
                detections = self.process_detections(results)
                
                # Dessiner les d√©tections
                if SHOW_DISPLAY:
                    frame = self.draw_detections(frame, detections)
                
                # V√©rifier si on doit d√©clencher le tri
                if detections:
                    best_detection = max(detections, key=lambda x: x['confidence'])
                    
                    if self.should_trigger_sort(best_detection):
                        waste_class = best_detection['class']
                        
                        # En mode apprentissage, demander confirmation
                        if LEARNING_MODE:
                            corrected_class = self.handle_correction(self.last_frame, best_detection)
                            if corrected_class is None:
                                continue  # Ignor√© par l'utilisateur
                            waste_class = corrected_class
                        
                        print(f"\nüéØ TRI AUTO D√âCLENCH√â : {waste_class}")
                        
                        # Utiliser waste_classifier pour le tri
                        # ask_if_unknown=True pour permettre d'apprendre
                        bin_color = waste_classifier.classify_and_sort(
                            waste_class,
                            ask_if_unknown=True,
                            auto_mode=False
                        )
                        
                        if bin_color:
                            print(f"‚úì Tri√© vers le bac {bin_color}")
                
                # Calculer les FPS
                fps_counter += 1
                if time.time() - fps_time > 1.0:
                    fps_display = fps_counter
                    fps_counter = 0
                    fps_time = time.time()
                
                # Afficher les infos sur l'image
                if SHOW_DISPLAY:
                    # Info FPS et d√©tections
                    info_text = f"FPS: {fps_display} | Detections: {len(detections)}"
                    cv2.putText(frame, info_text, (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    # Suivi de d√©tection
                    if self.last_detection:
                        status_text = f"Suivi: {self.last_detection['class']} ({self.detection_count}/{MIN_DETECTIONS})"
                        cv2.putText(frame, status_text, (10, 60), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                    
                    # Mode
                    mode_text = "Mode: Apprentissage" if LEARNING_MODE else "Mode: Auto"
                    cv2.putText(frame, mode_text, (10, FRAME_HEIGHT - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
                    
                    cv2.imshow('Smart Bin - Detection', frame)
                
                # G√©rer les entr√©es clavier
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q'):
                    print("\nüëã Arr√™t de la d√©tection...")
                    break
                
                elif key == ord('s'):
                    # Tri manuel forc√©
                    if detections:
                        best = max(detections, key=lambda x: x['confidence'])
                        waste_class = best['class']
                        print(f"\n‚ö° TRI MANUEL FORC√â : {waste_class}")
                        waste_classifier.classify_and_sort(
                            waste_class,
                            ask_if_unknown=True,
                            auto_mode=False
                        )
                
                elif key == ord('r'):
                    # R√©initialiser le compteur
                    self.detection_count = 0
                    self.last_detection = None
                    print("\n‚Üª Compteur de d√©tections r√©initialis√©")
                
                elif key == ord('c') and LEARNING_MODE:
                    # Corriger la derni√®re d√©tection
                    if self.last_detection:
                        corrected = self.handle_correction(
                            self.last_frame,
                            self.last_detection
                        )
                        if corrected:
                            bin_color = waste_classifier.ask_user_for_bin(corrected)
                            if bin_color:
                                waste_classifier.save_to_database(corrected, bin_color)
                
                # Commande textuelle pour stats
                # (Note: ne fonctionne que si on redirige stdin, sinon utiliser 's' dans le menu)
        
        except KeyboardInterrupt:
            print("\n\n‚ö† Interrompu par l'utilisateur")
        
        finally:
            # Nettoyage
            cap.release()
            if SHOW_DISPLAY:
                cv2.destroyAllWindows()
            
            waste_classifier.cleanup()
            
            print("\n‚úì Syst√®me de d√©tection arr√™t√©\n")


# ============================================
# POINT D'ENTR√âE PRINCIPAL
# ============================================

def main():
    """Ex√©cuter la d√©tection YOLO"""
    # D√©marrer l'interface administrateur automatiquement si demand√©
    if ADMIN_AUTOSTART:
        try:
            # V√©rifier si quelqu'un √©coute d√©j√† sur les ports admin et user
            s = socket.socket()
            s.settimeout(0.5)
            try:
                s.connect(("127.0.0.1", ADMIN_INTERFACE_PORT))
                s.close()
                print(f"‚Üí Interface admin d√©j√† en √©coute sur le port {ADMIN_INTERFACE_PORT}")
            except Exception:
                # Lancer le serveur admin_interface dans interfaces/
                admin_path = Path(__file__).resolve().parent.parent / 'interfaces' / 'admin_interface' / 'app.py'
                if admin_path.exists():
                    print(f"‚Üí Lancement automatique de l'interface admin ({admin_path})")
                    try:
                        subprocess.Popen([sys.executable, str(admin_path)], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                    except Exception as e:
                        print(f"‚ö† Impossible de lancer l'interface admin: {e}")

            # User interface
            try:
                s2 = socket.socket()
                s2.settimeout(0.5)
                s2.connect(("127.0.0.1", USER_INTERFACE_PORT))
                s2.close()
                print(f"‚Üí Interface utilisateur d√©j√† en √©coute sur le port {USER_INTERFACE_PORT}")
            except Exception:
                user_path = Path(__file__).resolve().parent.parent / 'interfaces' / 'user_interface' / 'app.py'
                if user_path.exists():
                    print(f"‚Üí Lancement automatique de l'interface utilisateur ({user_path})")
                    try:
                        subprocess.Popen([sys.executable, str(user_path)], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                    except Exception as e:
                        print(f"‚ö† Impossible de lancer l'interface utilisateur: {e}")
        except Exception:
            pass
    detector = WasteDetector()
    detector.run_camera_detection()


if __name__ == "__main__":
    main()