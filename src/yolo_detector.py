"""
Smart Bin SI - Module de D√©tection YOLO
Int√®gre YOLOv5/YOLOv8 pour la d√©tection temps-r√©el via cam√©ra
Remplace la saisie manuelle par la d√©tection automatique
"""

import cv2
import torch
import time
import numpy as np
from pathlib import Path
import sys

# Ajouter le script principal au path pour utiliser les fonctions de base de donn√©es
sys.path.append(str(Path(__file__).parent))

try:
    from waste_classifier import (
        init_database, 
        get_or_assign_bin_color, 
        send_sorting_command,
        init_serial_connection
    )
    MAIN_SCRIPT_AVAILABLE = True
except ImportError:
    print("‚ö† Attention : Script principal non trouv√©")
    MAIN_SCRIPT_AVAILABLE = False


# ============================================
# CONFIGURATION
# ============================================

# Configuration du mod√®le
MODEL_PATH = "models/best.pt"  # Chemin vers ton mod√®le YOLO entra√Æn√©
CONFIDENCE_THRESHOLD = 0.6     # Confiance minimum pour accepter une d√©tection
IOU_THRESHOLD = 0.45           # Seuil IoU pour la suppression non-maximale

# Configuration cam√©ra
CAMERA_SOURCE = 0  # 0 pour cam√©ra USB, ou "rtsp://..." pour cam√©ra IP
# Pour cam√©ra CSI Jetson, utiliser le pipeline gstreamer (voir ci-dessous)
USE_CSI_CAMERA = False

# Configuration affichage
SHOW_DISPLAY = True
FRAME_WIDTH = 640
FRAME_HEIGHT = 480

# Comportement de d√©tection
AUTO_SORT_DELAY = 2.0  # Secondes d'attente avant le tri auto d'un objet d√©tect√©
MIN_DETECTIONS = 3     # Nombre minimum de d√©tections cons√©cutives avant tri


# Mapping cat√©gorie de d√©chet ‚Üí couleur de bac
# Personnaliser selon les classes de ton mod√®le entra√Æn√©
WASTE_TO_BIN_MAPPING = {
    # Recyclable (Bac jaune)
    "plastic_bottle": "yellow",
    "cardboard": "yellow",
    "paper": "yellow",
    "metal_can": "yellow",
    "glass": "yellow",
    
    # Organique (Bac vert)
    "food_waste": "green",
    "organic": "green",
    "biodegradable": "green",
    
    # D√©chets g√©n√©raux (Bac marron)
    "general_waste": "brown",
    "non_recyclable": "brown",
    "mixed": "brown",
}


# ============================================
# SUPPORT CAM√âRA CSI JETSON
# ============================================

def get_csi_pipeline(camera_id=0, width=640, height=480, fps=30):
    """
    Cr√©er un pipeline GStreamer pour cam√©ra CSI Jetson
    
    Args:
        camera_id: ID du capteur cam√©ra (0 ou 1)
        width: Largeur de l'image
        height: Hauteur de l'image
        fps: Fr√©quence d'images
    
    Retourne:
        str: Cha√Æne de pipeline GStreamer
    """
    return (
        f"nvarguscamerasrc sensor-id={camera_id} ! "
        f"video/x-raw(memory:NVMM), width={width}, height={height}, "
        f"format=NV12, framerate={fps}/1 ! "
        f"nvvidconv flip-method=0 ! "
        f"video/x-raw, width={width}, height={height}, format=BGRx ! "
        f"videoconvert ! "
        f"video/x-raw, format=BGR ! appsink"
    )


# ============================================
# CLASSE D√âTECTEUR DE D√âCHETS
# ============================================

class WasteDetector:
    """
    Syst√®me de d√©tection de d√©chets bas√© sur YOLO
    S'int√®gre avec la base de donn√©es et le contr√¥leur Arduino existants
    """
    
    def __init__(self, model_path=MODEL_PATH):
        """
        Initialiser le d√©tecteur YOLO
        
        Args:
            model_path: Chemin vers les poids YOLO entra√Æn√©s (fichier .pt)
        """
        print("\n" + "="*50)
        print("ü§ñ SMART BIN SI - D√âTECTEUR YOLO")
        print("="*50)
        
        # Charger le mod√®le YOLO
        self.model = self.load_model(model_path)
        
        # Suivi des d√©tections
        self.last_detection = None
        self.detection_count = 0
        self.last_sort_time = 0
        
        # Initialiser la base de donn√©es et le port s√©rie si disponibles
        if MAIN_SCRIPT_AVAILABLE:
            self.serial_conn = init_serial_connection()
            self.db_conn, self.db_cursor = init_database()
        else:
            print("‚ö† Mode autonome (pas de DB/Arduino)")
            self.serial_conn = None
            self.db_conn = None
            self.db_cursor = None
        
        print("‚úì D√©tecteur initialis√©\n")
    
    def load_model(self, model_path):
        """
        Charger le mod√®le YOLO depuis un fichier
        Supporte YOLOv5 et YOLOv8 via torch.hub ou ultralytics
        """
        print(f"üì¶ Chargement du mod√®le depuis : {model_path}")
        
        if not Path(model_path).exists():
            print(f"‚ö† Fichier du mod√®le introuvable : {model_path}")
            print("   Utilisation du YOLOv5s par d√©faut (pr√©-entra√Æn√© sur COCO)")
            print("   Pour utiliser un mod√®le custom, entra√Æne-le d'abord !")
            
            # Charger YOLOv5s pr√©-entra√Æn√© comme solution de secours
            model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
        else:
            # Charger le mod√®le custom entra√Æn√©
            try:
                model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)
                print("‚úì Mod√®le custom charg√© avec succ√®s")
            except Exception as e:
                print(f"‚úó Erreur lors du chargement du mod√®le custom : {e}")
                print("   Retour au YOLOv5s pr√©-entra√Æn√©")
                model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
        
        # D√©finir les param√®tres du mod√®le
        model.conf = CONFIDENCE_THRESHOLD
        model.iou = IOU_THRESHOLD
        
        # Utiliser le GPU si disponible (important pour Jetson)
        if torch.cuda.is_available():
            model = model.cuda()
            print("‚úì Acc√©l√©ration GPU activ√©e")
        else:
            print("‚ö† Ex√©cution sur CPU (plus lent)")
        
        return model
    
    def detect_waste(self, frame):
        """
        Ex√©cuter la d√©tection YOLO sur une image
        
        Args:
            frame: Image OpenCV (format BGR)
        
        Retourne:
            results: R√©sultats de d√©tection YOLO
        """
        # Ex√©cuter l'inf√©rence
        results = self.model(frame)
        return results
    
    def process_detections(self, results):
        """
        Traiter les r√©sultats YOLO et extraire les d√©chets
        
        Args:
            results: R√©sultats de d√©tection YOLO
        
        Retourne:
            list: D√©chets d√©tect√©s avec [nom_classe, confiance, bbox]
        """
        detections = []
        
        # Extraire les r√©sultats (format d√©pend de YOLOv5 vs YOLOv8)
        try:
            # Format YOLOv5
            predictions = results.pandas().xyxy[0]
            
            for idx, row in predictions.iterrows():
                class_name = row['name']
                confidence = row['confidence']
                bbox = [row['xmin'], row['ymin'], row['xmax'], row['ymax']]
                
                detections.append({
                    'class': class_name,
                    'confidence': confidence,
                    'bbox': bbox
                })
        except:
            # Analyse alternative si pandas non disponible
            pred = results.xyxy[0].cpu().numpy()
            for detection in pred:
                x1, y1, x2, y2, conf, cls = detection
                class_name = self.model.names[int(cls)]
                
                detections.append({
                    'class': class_name,
                    'confidence': float(conf),
                    'bbox': [float(x1), float(y1), float(x2), float(y2)]
                })
        
        return detections
    
    def map_to_bin(self, waste_class):
        """
        Mapper une classe de d√©chet d√©tect√©e vers la couleur du bac
        
        Args:
            waste_class: Nom de la classe de d√©chet d√©tect√©e
        
        Retourne:
            str: Couleur du bac (yellow/green/brown) ou None si inconnu
        """
        # Mapping direct depuis la configuration
        if waste_class in WASTE_TO_BIN_MAPPING:
            return WASTE_TO_BIN_MAPPING[waste_class]
        
        # Solution de secours : v√©rifier la base de donn√©es si disponible
        if MAIN_SCRIPT_AVAILABLE and self.db_cursor:
            bin_color = get_or_assign_bin_color(
                self.db_cursor, 
                self.db_conn, 
                waste_class
            )
            return bin_color
        
        return None
    
    def should_trigger_sort(self, detection):
        """
        D√©cider si on doit d√©clencher l'action de tri
        Utilise un filtrage temporel pour √©viter les faux positifs
        
        Args:
            detection: Dictionnaire de d√©tection actuel
        
        Retourne:
            bool: True si on doit trier maintenant
        """
        current_time = time.time()
        
        # V√©rifier si assez de temps s'est √©coul√© depuis le dernier tri
        if current_time - self.last_sort_time < AUTO_SORT_DELAY:
            return False
        
        # V√©rifier si le m√™me objet est d√©tect√© plusieurs fois
        if detection and self.last_detection:
            if detection['class'] == self.last_detection['class']:
                self.detection_count += 1
            else:
                self.detection_count = 1
                self.last_detection = detection
        else:
            self.detection_count = 1
            self.last_detection = detection
        
        # D√©clencher si le minimum de d√©tections cons√©cutives est atteint
        if self.detection_count >= MIN_DETECTIONS:
            self.detection_count = 0
            self.last_sort_time = current_time
            return True
        
        return False
    
    def draw_detections(self, frame, detections):
        """
        Dessiner les bo√Ætes de d√©tection et labels sur l'image
        
        Args:
            frame: Image OpenCV
            detections: Liste des dictionnaires de d√©tection
        
        Retourne:
            frame: Image annot√©e
        """
        for det in detections:
            x1, y1, x2, y2 = [int(v) for v in det['bbox']]
            class_name = det['class']
            confidence = det['confidence']
            
            # Obtenir la couleur du bac pour ce d√©chet
            bin_color = self.map_to_bin(class_name)
            
            # Choisir la couleur d'affichage selon le bac
            if bin_color == "yellow":
                color = (0, 255, 255)  # Jaune en BGR
            elif bin_color == "green":
                color = (0, 255, 0)    # Vert
            elif bin_color == "brown":
                color = (0, 100, 200)  # Marron
            else:
                color = (128, 128, 128)  # Gris pour inconnu
            
            # Dessiner la bo√Æte
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # Dessiner le label
            label = f"{class_name} ({confidence:.2f})"
            if bin_color:
                label += f" -> {bin_color}"
            
            cv2.putText(frame, label, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        return frame
    
    def run_camera_detection(self):
        """
        Boucle principale : capturer images, d√©tecter d√©chets, d√©clencher tri
        """
        # Initialiser la cam√©ra
        if USE_CSI_CAMERA:
            print("üì∑ Ouverture cam√©ra CSI...")
            pipeline = get_csi_pipeline(width=FRAME_WIDTH, height=FRAME_HEIGHT)
            cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
        else:
            print(f"üì∑ Ouverture cam√©ra : {CAMERA_SOURCE}")
            cap = cv2.VideoCapture(CAMERA_SOURCE)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)
        
        if not cap.isOpened():
            print("‚úó √âchec d'ouverture de la cam√©ra")
            return
        
        print("‚úì Cam√©ra pr√™te")
        print("\n" + "="*50)
        print("CONTR√îLES :")
        print("  'q' - Quitter")
        print("  's' - Forcer le tri de la d√©tection actuelle")
        print("  'r' - R√©initialiser le compteur de d√©tections")
        print("="*50 + "\n")
        
        fps_time = time.time()
        fps_counter = 0
        fps_display = 0
        
        try:
            while True:
                # Capturer l'image
                ret, frame = cap.read()
                if not ret:
                    print("‚úó √âchec de lecture de l'image")
                    break
                
                # Ex√©cuter la d√©tection YOLO
                results = self.detect_waste(frame)
                detections = self.process_detections(results)
                
                # Dessiner les d√©tections
                if SHOW_DISPLAY:
                    frame = self.draw_detections(frame, detections)
                
                # V√©rifier si on doit d√©clencher le tri
                if detections:
                    best_detection = max(detections, key=lambda x: x['confidence'])
                    
                    if self.should_trigger_sort(best_detection):
                        waste_class = best_detection['class']
                        bin_color = self.map_to_bin(waste_class)
                        
                        if bin_color:
                            print(f"\nüéØ TRI AUTO D√âCLENCH√â : {waste_class} ‚Üí bac {bin_color}")
                            
                            if MAIN_SCRIPT_AVAILABLE and self.serial_conn:
                                send_sorting_command(self.serial_conn, bin_color)
                            else:
                                print(f"   [SIMULATION] Trierait vers {bin_color}")
                        else:
                            print(f"\n‚ö† Type de d√©chet inconnu : {waste_class}")
                
                # Calculer les FPS
                fps_counter += 1
                if time.time() - fps_time > 1.0:
                    fps_display = fps_counter
                    fps_counter = 0
                    fps_time = time.time()
                
                # Afficher les infos sur l'image
                if SHOW_DISPLAY:
                    info_text = f"FPS: {fps_display} | Detections: {len(detections)}"
                    cv2.putText(frame, info_text, (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    if self.last_detection:
                        status_text = f"Suivi: {self.last_detection['class']} ({self.detection_count}/{MIN_DETECTIONS})"
                        cv2.putText(frame, status_text, (10, 60), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                    
                    cv2.imshow('Smart Bin - Detection', frame)
                
                # G√©rer les entr√©es clavier
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("\nüëã Arr√™t de la d√©tection...")
                    break
                elif key == ord('s'):
                    if detections and MAIN_SCRIPT_AVAILABLE:
                        best = max(detections, key=lambda x: x['confidence'])
                        bin_color = self.map_to_bin(best['class'])
                        if bin_color:
                            print(f"\n‚ö° TRI MANUEL : {best['class']} ‚Üí {bin_color}")
                            send_sorting_command(self.serial_conn, bin_color)
                elif key == ord('r'):
                    self.detection_count = 0
                    self.last_detection = None
                    print("\n‚Üª Compteur de d√©tections r√©initialis√©")
        
        except KeyboardInterrupt:
            print("\n\n‚ö† Interrompu par l'utilisateur")
        
        finally:
            # Nettoyage
            cap.release()
            if SHOW_DISPLAY:
                cv2.destroyAllWindows()
            
            if MAIN_SCRIPT_AVAILABLE:
                if self.serial_conn:
                    self.serial_conn.close()
                if self.db_conn:
                    self.db_conn.close()
            
            print("\n‚úì Syst√®me de d√©tection arr√™t√©\n")


# ============================================
# POINT D'ENTR√âE PRINCIPAL
# ============================================

def main():
    """Ex√©cuter la d√©tection YOLO"""
    detector = WasteDetector()
    detector.run_camera_detection()


if __name__ == "__main__":
    main()